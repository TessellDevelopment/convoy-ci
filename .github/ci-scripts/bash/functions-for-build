#!/bin/bash

source ./ci-scripts/bash/functions-for-artifacts-upload
source ./ci-scripts/bash/functions-for-build-camel-case

assert_base_branch_commit_success() {
  echo "Checking base branch ${GITHUB_BASE_REF} commit build status"
  base_branch_commit=$(git log origin/${GITHUB_BASE_REF} -n 1 --format="%h")
  get_commit_build_status "${base_branch_commit}" "${GITHUB_BASE_REF}"
  if [[ "${COMMIT_BUILD_STATUS}" != "SUCCESSFUL" ]]; then
    echo "Base branch commit ${base_branch_commit} build status is ${COMMIT_BUILD_STATUS}.\nPlease check and re-trigger the pipeline."
    exit 1
  fi
}

assert_root_pr_commit_success() {
  get_commit_build_status "${base_branch_commit_of_root_pr}" "${base_branch_of_root_pr}"
  if [[ "${COMMIT_BUILD_STATUS}" != "SUCCESSFUL" ]]; then
    echo "Root PR commit ${base_branch_commit_of_root_pr} build status is ${COMMIT_BUILD_STATUS}.\nPlease check and re-trigger the pipeline."
    exit 1
  fi
}

aws_configure_devqa_infra() {
  aws configure set aws_access_key_id ${DEVQA_INFRA_ACCESS_KEY}
  aws configure set aws_secret_access_key ${DEVQA_INFRA_SECRET_KEY}
  aws configure set region ap-south-1
}

aws_configure_prod_assets() {
  aws configure set aws_access_key_id ${PROD_ASSET_ACCESS_KEY}
  aws configure set aws_secret_access_key ${PROD_ASSET_SECRET_KEY}
  aws configure set region ap-south-1
}

aws_configure_tessellops_artifacts() {
  aws configure set aws_access_key_id ${TESSELLOPS_ARTIFACTS_DEV_ACCESS_KEY}
  aws configure set aws_secret_access_key ${TESSELLOPS_ARTIFACTS_DEV_SECRET_KEY}
  aws configure set region ap-south-1
}

bash_build() {
  set -e
  DIR="${1}"
  export PATH=$PATH:/home/github/.local/bin
  ./$DIR/build.sh
  set +e
}

bash_build_and_push() {
  set -e
  bash_build "$@"
  ARTIFACT="${1}"
  EXTENSION="${2}"
  push_release_manifest_artifacts
  set +e
}


build_convoy_tessell_client() {
  install_go_dependencies
  ./setup --client --version 0.0.0
}

build_convoy_tessell_client_and_push() {
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@"
  install_go_dependencies
  ./setup --client --version ${LATEST_TAG} --upload-to-nexus $(${DEV_BUILD} || echo "--prod")
}

build_convoy_tessell_image() {
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@"
  install_go_dependencies
  python -m pip install build
  bash ./setup -i
}

build_convoy_tessell_image_and_push() {
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@"
  IMAGE="${1}"
  build_convoy_tessell_image  "$@"
  docker_tag_and_push "${IMAGE}" "${LATEST_TAG}"
}

check_convoy_yaml() {
  if ! [[ -f "convoy.yaml" ]]; then
    echo "Error: File 'convoy.yaml' not found." >&2
    return 1
  fi
}

check_flyway() {
  if [ -d "flyway" ]; then
    echo "The 'flyway' directory exists in this repository."
    DOCKER_FLYWAY_IMAGE_NAME=$(echo ${GITHUB_REPOSITORY%-*} | cut -f2 -d'/')-flyway-migration
    docker tag ${DOCKERHUB_ORG}/${DOCKER_FLYWAY_IMAGE_NAME}:latest ${DOCKERHUB_ORG}/${DOCKER_FLYWAY_IMAGE_NAME}:${LATEST_TAG}
    docker push ${DOCKERHUB_ORG}/${DOCKER_FLYWAY_IMAGE_NAME}:${LATEST_TAG}
  else
    echo "The 'flyway' directory does not exists in this repository."
  fi
}

is_pyenv_entity_exists() {
  pyenv versions --bare | grep -q "^${1}"
}

configure_python_version_if_required() {
  check_convoy_yaml
  echo "Checking for python version in convoy.yaml..."
  required_python_version=$(yq e '.pythonVersion // ""' convoy.yaml 2>/dev/null)
  echo "required_python_version: ${required_python_version}"
  [[ -n "${required_python_version:-}" ]] || return 0
  echo "Python version declared in convoy.yaml: ${required_python_version}" >&2

  if ! is_pyenv_entity_exists "${required_python_version}";  then
    echo "Python ${required_python_version} not found. Installing..."
    pyenv install "${required_python_version}"
  fi

  env_name="build-${required_python_version}"

  if ! is_pyenv_entity_exists "${env_name}"; then
    echo "Creating virtualenv ${env_name}..."
    pyenv virtualenv "${required_python_version}" "${env_name}"
  fi
  source ${HOME}/.sourcables
  pyenv shell "${env_name}"
  echo "Activated pyenv environment: ${env_name}"
  python --version
}

configure_go_version_if_required() {
  check_convoy_yaml
  required_go_version=$(yq e '.goVersion // ""' convoy.yaml 2>/dev/null)
  [[ -n ${required_go_version:-} ]] || return
  echo "Go version declared in convoy.yaml: ${required_go_version}" >&2
  if ! is_go_version_installed ${required_go_version}; then
    echo "Go lang version ${required_go_version} is not installed."
    gvm install ${required_go_version}
  fi
  gvm use ${required_go_version}
  export GOROOT="/home/github/.gvm/versions/go${required_go_version}.linux.amd64"
  export PATH="${GOROOT}/bin:${PATH}"
  echo "GOROOT = ${GOROOT}"
  echo "PATH = ${PATH}"
  go version
}

configure_npmrc(){
  set +e 
  REPO="${1}"
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@" 
  rm ~/.npmrc
  TOKEN=$(echo -n "${NEXUS_USERNAME}:${NEXUS_PASSWORD}" | base64 -w 0)
  echo "//${NEXUS_SERVER_ENDPOINT}/repository/:_auth = ${TOKEN}" >> ~/.npmrc
  echo "//${NEXUS_SERVER_ENDPOINT}/repository/:always-auth = true" >> ~/.npmrc 
  echo "@tessell:registry=${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${REPO}" >> ~/.npmrc
  cat ~/.npmrc
}

configure_npmrc_yarnrc() {
  set +e
  rm ~/.npmrc
  rm ~/.yarnrc
  TOKEN=$(echo -n "${NEXUS_USERNAME}:${NEXUS_PASSWORD}" | base64 -w 0)
  echo "\"@tessell:registry\" \"${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PUSH_REPOS_NPM}/\"" >> .yarnrc
  echo "always-auth=true" >> .npmrc
  echo "_auth=${TOKEN}" >> .npmrc
  cat .npmrc
  cat .yarnrc
} 

configure_and_push_aws() {
  BUCKET_ACCOUNT=${1}
  BUCKET_NAME=${2}
  SOURCE=${3}
  DESTINATION=${4}
  generate_sts_session_token ${BUCKET_ACCOUNT}
  aws s3 cp "${SOURCE}" "${DESTINATION}"
  unset AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN
}

convoy_build() {
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@"
  bash ./setup 
}

convoy_build_and_push() {
  
  ARTIFACT="${1}"
  EXTENSION="${2}"
  convoy_build "$@"
  if [[ ${APP_GROUP} == ${TESSELL_GCP_APP_NAME} ]]; then
    push_to_gcloud "./build/${ARTIFACT}.${EXTENSION}" "gs://${TESSELL_GCP_ARTIFACTS_BUCKET}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}"
    
  elif [[ ${APP_GROUP} == ${TESSELLOPS_APP_NAME} ]]; then
    aws_configure_tessellops_artifacts
    push_to_nexus "./build/${ARTIFACT}.${EXTENSION}" "${NEXUS_REPO_TESSELLOPS_ARTIFACTS}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION}"
    mv ./build/${ARTIFACT}.${EXTENSION}  ${ARTIFACT}.${EXTENSION}
    aws s3 cp ${ARTIFACT}.${EXTENSION} s3://${TESSELLOPS_ARTIFACTS_DEV_S3}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION} 

  elif [[ ${APP_GROUP} == ${TESSELL_APP_NAME} ]]; then
    mv ./build/${ARTIFACT}.${EXTENSION}  ${ARTIFACT}.${EXTENSION}
    push_to_nexus "./build/${ARTIFACT}.${EXTENSION}" "${NEXUS_REPO_TESSELL_ARTIFACTS}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION}"
    push_release_manifest_artifacts

  elif [[ ${APP_GROUP} == ${CITEST_APP_NAME} ]]; then
    mv ./build/${ARTIFACT}.${EXTENSION}  ${ARTIFACT}.${EXTENSION}
    push_to_nexus "./build/${ARTIFACT}.${EXTENSION}" "${NEXUS_REPO_TESSELL_ARTIFACTS}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION}"
    push_release_manifest_artifacts
  fi
  generate_checksum $ARTIFACT "${ARTIFACT}.${EXTENSION}"
  
}

convoy_codegen_build() {
  set -e
  ARTIFACT="${1}"
  VERSION="${3}"
  cd ./${ARTIFACT}
  mvn clean package -Drevision=${VERSION:-0.0.0}
  cd ..
  set +e
}

convoy_codegen_build_and_push() {
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  VERSION="${3}"
  convoy_codegen_build $@
  set -e
  ARTIFACT_PATH="./${ARTIFACT}/target/${ARTIFACT}-${VERSION}.${EXTENSION}"
  mvn_deploy "${ARTIFACT}" "${EXTENSION}" "${ARTIFACT_PATH}" "convoy.code-generator" "${VERSION}"
  set +e
}


convoy_go_library_build() {
  set -e
  go build ./...
  set +e
}

create_tf_backend() {
  S3_BUCKET="$1"
  KEY="$2"
  AWS_ACCESS_KEY_ID="$3"
  AWS_SECRET_ACCESS_KEY="$4"
  AWS_REGION="ap-south-1"
  cat <<EOL > "backend.tf"
  terraform {
    backend "s3" {
      bucket               = "${S3_BUCKET}"
      key                  = "${KEY}"
      region               = "${AWS_REGION}"
      access_key           = "${AWS_ACCESS_KEY_ID}"
      secret_key           = "${AWS_SECRET_ACCESS_KEY}"
      encrypt              = true
    }
  }
EOL
}

docker_build() {
  set -e
  IMAGE="${1}"
  FILE="${4}"
  if [[ "${FILE}" == "null" || -z "${FILE}" ]]; then
    FILE="./Dockerfile"
  fi
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@" 
  docker build -f ${FILE} -t ${IMAGE} \
              --build-arg GITHUB_USER=${GITHUB_USER} \
              --build-arg GITHUB_TOKEN=${GITHUB_TOKEN} \
              --build-arg NEXUS_PROTOCOL=${NEXUS_PROTOCOL} \
              --build-arg NEXUS_SERVER_ENDPOINT=${NEXUS_SERVER_ENDPOINT} \
              --build-arg NEXUS_USERNAME=${NEXUS_USERNAME} \
              --build-arg NEXUS_PASSWORD=${NEXUS_PASSWORD} .
  image_scan ${IMAGE}
  set +e
}

docker_build_and_push() {
  set -e
  IMAGE="${1}"
  VERSION="${3}"
  FILE="${4}"
  TAG=${LATEST_TAG}
  if [[ "${VERSION}" != "null" && -n "${VERSION}" ]]; then
    TAG=${VERSION}
  fi
  if [[ "${FILE}" == "null" || -z "${FILE}" ]]; then
    FILE="./Dockerfile"
  fi
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@" 
  docker build -f ${FILE} -t ${IMAGE} \
              --build-arg GITHUB_USER=${GITHUB_USER} \
              --build-arg GITHUB_TOKEN=${GITHUB_TOKEN} \
              --build-arg NEXUS_PROTOCOL=${NEXUS_PROTOCOL} \
              --build-arg NEXUS_SERVER_ENDPOINT=${NEXUS_SERVER_ENDPOINT} \
              --build-arg NEXUS_USERNAME=${NEXUS_USERNAME} \
              --build-arg NEXUS_PASSWORD=${NEXUS_PASSWORD} .
  docker_tag_and_push "${IMAGE}" "${TAG}"
  set +e
}

docker_tag_and_push() {
  IMAGE="${1}"
  TAG="${2}"
  docker tag ${IMAGE}:latest ${DOCKERHUB_ORG}/${IMAGE}:${TAG}
  docker push ${DOCKERHUB_ORG}/${IMAGE}:${TAG}
}

download_binary_from_source() {
  CONFIG_FILE="convoy.yaml"
  TMP_DIR="/tmp"
  if [[ "$(yq '.externalUrls' "${CONFIG_FILE}")" != "null" ]]; then
    echo "Error: 'externalUrls' is deprecated. Please switch to 'dataSources' for downloading binaries in the Terraform module. Failing build."
    exit 1
  fi
  if [[ $(yq eval 'has("dataSources")' "${CONFIG_FILE}") == "true" ]]; then
    echo "dataSources found in ${CONFIG_FILE}. Processing artifacts."
    data_sources=$(yq eval -o=json '.dataSources' "${CONFIG_FILE}" | jq -c '.[]')
    for entry in ${data_sources}; do

      http_url=$(echo "${entry}" | jq -r '.source.httpPublicUrl // empty')
      minio_path=$(echo "${entry}" | jq -r '.source.tessellArtifactsPath // empty')

      local_path=$(echo "${entry}" | jq -r '.destination.localPath')
      extract_source=$(echo "${entry}" | jq -r '.destination.extractSource')

      filename=$(basename "${http_url:-${minio_path}}")
      download_path="${TMP_DIR}/${filename}"

      if [[ -n "${http_url}" ]]; then
        echo "Downloading from HTTP: ${http_url}"
        wget -q "${http_url}" -O "${download_path}"
      elif [[ -n "${minio_path}" ]]; then
        echo "Downloading from MinIO: ${minio_path}"
        mc cp "minio_ci/tessell-artifacts-dev/${minio_path}" "${download_path}"
      else
        echo "No valid source found for entry: ${entry}"
        exit 1
      fi
      if [[ "${extract_source}" == "true" ]]; then
        mkdir -p "${local_path}"
        echo "Extracting ${download_path} to ${local_path}"
        case "${download_path}" in
          *.zip) unzip -o "${download_path}" -d "${local_path}" ;;
          *.tar) tar -xf "${download_path}" -C "${local_path}" ;;
          *.tar.gz|*.tgz) tar -xzf "${download_path}" -C "${local_path}" ;;
          *) echo "Unsupported archive format: ${download_path}"; exit 1 ;;
        esac
      else
        mkdir -p $(dirname "${local_path}")
        echo "Copying ${download_path} to ${local_path}"
        cp "${download_path}" "${local_path}"
        mode=$(echo "${entry}" | jq -r '.destination.mode // 644')
        chmod "${mode}" "${local_path}"
      fi
      rm "${download_path}"
      echo "Processing complete for ${filename}"
    done
  else
    echo "No dataSources defined in ${CONFIG_FILE}. Moving on..."
  fi
}

elastic_agent_build() {
  set -e
  IMAGE="${1}"
  GOOS=linux GOARCH=amd64 go build .
  docker_build "$@"
  set +e
}

elastic_agent_build_and_push() {
  set -e
  IMAGE="${1}"
  GOOS=linux GOARCH=amd64 go build .
  docker_build_and_push "$@"
  set +e
}

frp_build() {
  set -e
  ./setup -b
  set +e
}

frp_build_and_push() {
  frp_build
  set -e
  EXTENSION="${2}"
  os_type=("linux" "windows")
  for OS in "${os_type[@]}"; do
    ARTIFACT="tessell-frpc-${OS}"
    mvn_deploy "${ARTIFACT}" "${EXTENSION}" "./${ARTIFACT}.${EXTENSION}" "tessell.frp" "${LATEST_TAG}"
    push_release_manifest_artifacts
  done
  set +e
}

folder_content_and_push() {
  export ARTIFACT=${1}
  check_convoy_yaml
  local artifact_json=$(yq -o=json '.generates.artifacts[] | select(.name == env(ARTIFACT))' convoy.yaml)
  local folder_path=$(echo "$artifact_json" | jq -r .folderPath)
  local recursive=$(echo $artifact_json | jq -r .recursive)
  upload_folder_to_gcloud "$folder_path" "$recursive" "$RELEASE_LABEL" "$RELEASE_VERSION"
  generate_checksum $ARTIFACT.zip
}

get_base_branch_commit_from_pr_number() {
  base_branch_commit_of_root_pr=$(curl -L \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer ${GITHUB_TOKEN}" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  "${GH_API_URL}/repos/${REPOSITORY}/pulls/${root_pr_number}"| jq -r '.merge_commit_sha')
}

get_dc_messages() {
  dc_message=$(curl -L \
  -H "Accept: application/vnd.github+json" \
  -H "Authorization: Bearer ${GITHUB_TOKEN}" \
  -H "X-GitHub-Api-Version: 2022-11-28" \
  "${GH_API_URL}/repos/${REPOSITORY}/pulls/${PR_NUMBER}/commits"| jq -r '.[0].commit.message' | head -n 1)
}

get_root_pr_tag() {
  get_dc_messages
  root_pr_number=$(echo ${dc_message} | grep -oE '[0-9]+' | tail -1 )
  echo "root_pr_number" ${root_pr_number}
  get_base_branch_commit_from_pr_number
  echo "base branch commit" ${base_branch_commit_of_root_pr}
  git diff ${base_branch_commit_of_root_pr}^!
  root_pr_tag=$(git tag --contains ${base_branch_commit_of_root_pr} | sort -V | head -n 1)
  base_branch_of_root_pr="rel-$(echo "${root_pr_tag}" | cut -d. -f1,2).0"
}

get_commit_build_status() {
  check_convoy_yaml
  commit_hash="${1}"
  base_branch="${2}"
  app_group=$(yq '.appGroup' convoy.yaml)
  response=$(curl --write-out "\n%{http_code}" --location --request GET "${DEVOPS_GIT_METADATA_API_ENDPOINT}/apps/${app_group}/commits/${commit_hash}?baseBranch=${base_branch}" \
    --header 'Content-Type: application/json' \
    --header "x-api-key: ${CONVOY_API_KEY}" \
    --data '')
  echo "response" ${response}
  JSON_BODY=$(echo "$response" | sed '$d')
  validate_reponse_code "$(echo "${response}" | tail -n1)" "200"
  COMMIT_BUILD_STATUS=$(echo "${JSON_BODY}" | jq -r '.response.buildStatus')
  COMMIT_TAG=$(echo "${JSON_BODY}" | jq -r '.response.tag')
  echo "build_status" ${COMMIT_BUILD_STATUS}
}

get_dc_root_pr_diff() {
  get_root_pr_tag
  git diff ${base_branch_commit_of_root_pr}^! --compact-summary  > ../root_pr_diff
  cat ../root_pr_diff
}

generate_checksum() {
  ARTIFACT=${1}
  BUILD_FILE=${2}
  if [[ -z "${BUILD_FILE}" ]]; then
    echo "Build File name same as Artifact name"
    BUILD_FILE=${ARTIFACT}
  fi
  file_path=$(find . -type f -name "${BUILD_FILE}" 2>/dev/null | head -n 1)
  if [[ -z "${file_path}" ]]; then
    echo "File not found!"
    return 1
  fi
  checksum=$(md5sum "${file_path}" | awk '{ print $1 }')
  ARTIFACT="${ARTIFACT%%.*}"
  ARTIFACT_CHECKSUMS+="${ARTIFACT}:${checksum}%"
}

generate_sts_session_token() {
  BUCKET_ACCOUNT=${1}
  unset AWS_SESSION_TOKEN AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY 
  export AWS_ACCESS_KEY_ID=${ARTIFACTS_UPLOAD_ACCESS_KEY}
  export AWS_SECRET_ACCESS_KEY=${ARTIFACTS_UPLOAD_SECRET_KEY}
  ROLE_ARN=arn:aws:iam::${BUCKET_ACCOUNT}:role/artifacts-bucket-update-role
  ROLE_OUTPUT=$(aws sts assume-role --role-arn ${ROLE_ARN} --role-session-name session)
  export AWS_ACCESS_KEY_ID=$(echo ${ROLE_OUTPUT} | jq -r '.Credentials.AccessKeyId')
  export AWS_SECRET_ACCESS_KEY=$(echo ${ROLE_OUTPUT} | jq -r '.Credentials.SecretAccessKey')
  export AWS_SESSION_TOKEN=$(echo ${ROLE_OUTPUT} | jq -r '.Credentials.SessionToken')
}

get_release_branch() {
  if [ -z "$1" ]; then
    echo "Error: No version string provided."
    return 1
  fi
  local VERSION_STRING="$1"
  MAJOR_MINOR=$(echo "$VERSION_STRING" | cut -d. -f1,2)
  REL_TAG="rel-${MAJOR_MINOR}.0"
  export REL_TAG="$REL_TAG"
}

get_previous_commited_software_manifest() {
  get_release_branch "${COMMIT_TAG}"
  minio_path="${REL_TAG}/software-image-manifest/software-image-manifest-${COMMIT_TAG}.json"
  echo "starting previous manifest download ${minio_path}"
  download_path="${WORKDIR}/software-image-manifest.json"
  mc cp "minio_ci/tessell-artifacts-dev/${minio_path}" "${download_path}"
}

go_docker_build() {
  set -e
  IMAGE="${1}"
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@" 
  install_go_dependencies
  echo "Building the service"
  export PATH=${PATH}:${GOPATH}/bin
  git config --global url."https://${GITHUB_USER}:${GITHUB_TOKEN}@github.com".insteadOf "https://github.com"
  ./setup -g -i
  image_scan ${IMAGE}
  set +e
}

go_docker_build_and_push() {
  set -e
  IMAGE="${1}"
  install_go_dependencies
  echo "Building the service"
  export PATH=${PATH}:${GOPATH}/bin
  git config --global url."https://${GITHUB_USER}:${GITHUB_TOKEN}@github.com".insteadOf "https://github.com"
  ./setup -g -i
  docker tag ${IMAGE}:latest ${DOCKERHUB_ORG}/${IMAGE}:${LATEST_TAG}
  docker push ${DOCKERHUB_ORG}/${IMAGE}:${LATEST_TAG}
  check_flyway ${IMAGE}
  set +e
}

go_library_build() {
  make_service "$@"
}

go_library_build_and_push() {
  make_service_and_push "$@"
}

gradlew_build() {
  ./gradlew build --console plain \
    -Pnexus_username="${NEXUS_USERNAME}" \
    -Pnexus_password="${NEXUS_PASSWORD}" \
    -Pnexus_pull_repo_m2="${NEXUS_PULL_REPOS_M2}"
}

gradlew_pythonwheel() {
  set -e
  ./gradlew pythonWheel docker --console plain \
    -Pnexus_username="${NEXUS_USERNAME}" \
    -Pnexus_password="${NEXUS_PASSWORD}"
  set +e
}

gradlew_build_and_push() {
  ./gradlew build publish --console plain \
    -Pnexus_push_username="${NEXUS_USERNAME}" \
    -Pnexus_push_password="${NEXUS_PASSWORD}" \
    -Pnexus_username="${NEXUS_USERNAME}" \
    -Pnexus_password="${NEXUS_PASSWORD}" \
    -Pnexus_push_repo_m2="${NEXUS_PUSH_REPOS_M2}" \
    -Pnexus_pull_repo_m2="${NEXUS_PULL_REPOS_M2}"
}

gradlew_docker_tag() {
  ./gradlew dockerTag --console plain \
    -Pnexus_username="${NEXUS_USERNAME}" \
    -Pnexus_password="${NEXUS_PASSWORD}" \
    -Pdockerhub_org="${DOCKERHUB_ORG}"
}

gradlew_ui_build() {
  configure_npmrc_yarnrc
  install_node
  set -e
  ENV_JSON=${TESSELL_UI_ENV_SECRET}
  echo $ENV_JSON | jq -r 'to_entries | .[] | "\(.key)=\"\(.value)\"" ' | sed '1s/^/\n/' >> .env
  cat .env
  ./gradlew zipUiBuild --console plain --stacktrace \
    -Pnexus_username="${NEXUS_USERNAME}" \
    -Pnexus_password="${NEXUS_PASSWORD}"
  set +e
}

gradlew_ui_build_and_push() {
  ARTIFACT=${1}
  EXTENSION=${2}
  gradlew_ui_build "$@"
  set -e
  ./gradlew publish --console plain \
    -Pnexus_push_username="${NEXUS_USERNAME}" \
    -Pnexus_push_password="${NEXUS_PASSWORD}" \
    -Pnexus_username="${NEXUS_USERNAME}" \
    -Pnexus_password="${NEXUS_PASSWORD}" \
    -Pnexus_push_repo_m2="${NEXUS_PUSH_REPOS_M2}" \
    -Pnexus_pull_repo_m2="${NEXUS_PULL_REPOS_M2}" \
    -Pnexus_push_repo_raw_ops=="${NEXUS_REPO_TESSELLOPS_ARTIFACTS}" \
    -Pnexus_endpoint="${NEXUS_SERVER_ENDPOINT}" \
    -Pnexus_protocol="${NEXUS_PROTOCOL}" \
    -Plabel="${LABEL}" 
  lib=$(cat settings.gradle | grep rootProject.name | sed "s/rootProject.name = '\(.*\)'/\1/")
  build_file_name=$(find . -type f -regex ".*${lib}-.*\.zip" -exec basename {} \;)
  push_release_manifest_artifacts ${build_file_name} "./build/libs/${build_file_name}"
  set +e
}

image_scan(){
  set -e
  export IMAGE="${1}"
  RETRIES=50
  TIMEOUT=600s
  for ((i=1; i<=RETRIES; i++)); do
    output=$(trivy image -f json -o trivy_image_scan_result.json --severity HIGH,CRITICAL --scanners vuln ${IMAGE}:latest 2>&1 || true)
    exit_code=$?
    echo ${output}
    if echo "${output}" | grep -q "TOOMANYREQUESTS"; then
        echo "Encountered TOOMANYREQUESTS error. Retrying."
        sleep 15
    elif [ ${exit_code} -eq 0 ]; then
        echo "Trivy scan completed successfully."
        break
    else
        echo "Trivy scan failed with exit code ${exit_code}: ${output}"
        exit 1
    fi
  done
  if [ ${i} -gt ${RETRIES} ]; then
    echo "Trivy scan failed after ${RETRIES} attempts."
    exit 1
  fi
  dockle -f json -o dockle_image_scan_result.json ${IMAGE}:latest --timeout ${TIMEOUT}
  python3 ./ci-scripts/python/image_scan.py
  set +e
}

initialise_coverage() {
  echo "Setting up virtual environment for running unit tests."
  venv_name=${1}
  venv_path=${PWD}/${venv_name}
  python_version=$(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
  source_path=${venv_path}/lib/python${python_version}/site-packages/
  python -m venv ${venv_name}
  source ${venv_name}/bin/activate
  dist_dir=$(find . -type d -name "dist" 2>/dev/null | head -n 1)
  python -m pip install "${dist_dir}"/*.whl coverage==7.5.1 requests-mock==1.12.1 pytest-env==1.1.3 pytest==8.2.0 --extra-index-url=${NEXUS_PROTOCOL}://${NEXUS_USERNAME}:${NEXUS_PASSWORD}@${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PULL_REPOS_PY}/simple --trusted-host ${NEXUS_SERVER_ENDPOINT}
  python -m pip list | grep tessell
  echo ${source_path}
  test_dir=$(yq '.codeCoverage.testsDirectory' convoy.yaml)
  if [ -z "${test_dir}" ] || [ "${test_dir}" = "null" ]; then
    test_dir=$(find . -type d -name "tests" 2>/dev/null | head -n 1)
  fi
  rm -rf ${source_path}/tests
  cp -r ${test_dir} pytest.ini ${source_path}
}

initialize_python_build_env() {
  set -e
  ARTIFACT=${1}
  requiredInputs="1"
  validateInputs "$requiredInputs" "$@"
  configure_python_version_if_required
  install_python_dependencies "$ARTIFACT"
  lintCheck
  set +e
}

install_go_dependencies() {
  go version
  go install golang.org/x/tools/cmd/goimports@v0.24.0
  which go
  go env
}

install_minio_client() {
  wget https://dl.min.io/client/mc/release/linux-amd64/mc
  sudo mv ./mc /usr/local/bin/mc
  chmod +x /usr/local/bin/mc
  export PATH=$PATH:/usr/local/bin
  mc --version
  while true; do
    response=$(mc alias set minio_ci ${CONVOY_MINIO_ENDPOINT} ${CONVOY_MINIO_ACCESS_KEY} ${CONVOY_MINIO_SECRET_KEY} 2>&1)
    echo "$response"
    if echo "$response" | grep -q "successfully"; then
        echo "Command succeeded: Added 'minio_ci' successfully."
        break
    else
        echo "Command failed, retrying..."
        sleep 2
    fi
  done  
  mc alias list
}

install_node() {
  export NVM_DIR="$HOME/.nvm"
  [ -s "$NVM_DIR/nvm.sh" ] && \. "$NVM_DIR/nvm.sh"
  [ -s "$NVM_DIR/bash_completion" ] && \. "$NVM_DIR/bash_completion"
  base_node_version=$(node --version)
  export base_node_version
  node_version=$(yq eval '.nodeVersion // strenv(base_node_version)' convoy.yaml)
  nvm which "$node_version" > /dev/null 2>&1
  if [ $? -eq 0 ]; then
    echo "Node version $node_version is already installed."
  else
    echo "Node version $node_version not found. Installing..."
    nvm install "$node_version"
  fi
  nvm use ${node_version}
}

install_python_dependencies() {
  DIR=${1}
  if [[ -z "${DIR}" ]]; then
    DIR='.'
  fi
  python -m pip install --upgrade pip
  python -m pip install flake8==5.0.4 pytest==7.1.1 twine==5.1.1 wheel==0.38.4
  if [ -f "${DIR}/requirements.txt" ]; then
    python -m pip install -r "${DIR}/requirements.txt" --trusted-host ${NEXUS_SERVER_ENDPOINT} --extra-index-url=${NEXUS_PROTOCOL}://${NEXUS_USERNAME}:${NEXUS_PASSWORD}@${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PULL_REPOS_PY}/simple
  fi
}

is_go_version_installed() {
  local required_version=${1}
  installed_versions=$(gvm list)
  for go_version in ${installed_versions[@]}; do
      if [[ ${go_version} == ${required_go_version} ]]; then
        return 0
      fi
  done
  return 1
}

jar_build() {
  set -e
  VERSION="${3}"
  required_inputs="3"
  validate_inputs "${required_inputs}" "$@" 
  ./mvnw package -Drevision=${VERSION}
  set +e
}

jar_build_and_push() {
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  VERSION="${3}"
  required_inputs="1 2 3"
  validate_inputs "${required_inputs}" "$@" 
  ./mvnw clean deploy -Drevision=${VERSION} -Dnexus_username=${NEXUS_USERNAME} -Dnexus_password=${NEXUS_PASSWORD} \
    -DgeneratePom=true -Dpackaging=${EXTENSION} -DrepositoryId=nexus \
    -DgroupId=tessellops -DartifactId=${ARTIFACT} \
    -DaltDeploymentRepository=nexus::default::${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PUSH_REPOS_M2}
  generate_checksum $ARTIFACT "${ARTIFACT}-${VERSION}.${EXTENSION}"
  set +e
}

make_service() {
  set -e
  ARTIFACT="${1}"
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@"
  NAME=$(echo "${ARTIFACT}" | awk -F '-linux' '{print $1}')
  if [ "${NAME}" == "${ARTIFACT}" ]; then
      NAME=$(echo "${ARTIFACT}" | awk -F '-windows' '{print $1}')
      OS="windows"
  else
      OS="linux"
  fi
  ENGINE=$(echo "${ARTIFACT}" | awk -F "${NAME}-${OS}" '{gsub(/^-|-linux|-windows$/, "", $2); print $2}')
  echo "Name: ${NAME}, OS: ${OS}, Engine: ${ENGINE}"
  if [[ "${ENGINE}" == "null" || -z "${ENGINE}" ]]; then
    make service os=${OS}
  else
    make service os=${OS} engine=${ENGINE}
  fi
  set +e
}

make_service_and_push() {
  make_service "$@"
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  mvn_deploy "${ARTIFACT}" "${EXTENSION}" "${ARTIFACT}.${EXTENSION}" "tessell.${NAME}" "${LATEST_TAG}"
  push_release_manifest_artifacts
  set +e
}

mvn_deploy() {
  ARTIFACT_ID="${1}"
  EXTENSION="${2}"
  FILE="${3}"
  GROUP_ID="${4}"
  VERSION="${5}"
  required_inputs="1 2 3 4 5"
  validate_inputs "${required_inputs}" "$@" 
  mvn deploy:deploy-file -Dnexus_url=${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/tessell-m2-component \
      -Dnexus_username=${NEXUS_USERNAME} -Dnexus_password=${NEXUS_PASSWORD} \
      -DgroupId=${GROUP_ID} -DartifactId=${ARTIFACT_ID} -Dversion=${VERSION} \
      -DgeneratePom=true -Dpackaging=${EXTENSION} \
      -Durl=${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PUSH_REPOS_M2} \
      -Dfile=${FILE} -DrepositoryId=nexus
}

mvnw_build() {
  set -e
  ./mvnw install -Dnative -DskipTests -Dquarkus.native.remote-container-build=true
  set +e
}

mvnw_build_and_push() {
  set -e
  ARTIFACT="${1}"
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@"
  mvnw_build
  if [[ ${APP_GROUP} == ${TESSELL_GCP_APP_NAME} ]]; then
    push_to_gcloud "./target/${ARTIFACT}" "gs://${TESSELL_GCP_ARTIFACTS_BUCKET}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}"
    generate_checksum $ARTIFACT
  else
    aws_configure_tessellops_artifacts
    push_to_nexus "./target/function.zip" "${NEXUS_REPO_TESSELLOPS_ARTIFACTS}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.zip"
    mv ./target/function.zip  ${ARTIFACT}-${LATEST_TAG}.zip
    aws s3 cp ${ARTIFACT}-${LATEST_TAG}.zip s3://${TESSELLOPS_ARTIFACTS_DEV_S3}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.zip   
    generate_checksum $ARTIFACT "${ARTIFACT}-${LATEST_TAG}.zip"
  fi
  set +e
}

npm_build() {
  install_node
  set -e
  npm install
  npm run build
  configure_npmrc "${NEXUS_REPO_NPM}"
  set -e
  version="${3}"
  required_inputs="3"
  validate_inputs "${required_inputs}" "$@" 
  yq ".version = \"${version}\"" package.json > tmp_package.json
  mv tmp_package.json package.json
  npm publish   
  set +e
}

npm_build_and_push() {
  install_node
  set -e
  npm install
  npm run build
  configure_npmrc "${NEXUS_PUSH_REPOS_NPM}"
  set -e
  version="${3}"
  required_inputs="3"
  validate_inputs "${required_inputs}" "$@" 
  yq ".version = \"${version}\"" package.json > tmp_package.json
  mv tmp_package.json package.json
  npm publish   
  set +e
}

ops_image_build() {
  set -e
  mvnw_build
  docker_build "$@"
  set +e
}

ops_image_build_and_push() {
  set -e
  IMAGE="${1}"
  ./mvnw install -Dnative -DskipTests -Dquarkus.native.remote-container-build=true
  docker_build_and_push "$@"
  set +e
}

ops_terraform_build() {
  set -x
  ARTIFACT="${1}"
  terraform_zip_build ${ARTIFACT} $PWD "."
}

ops_terraform_build_and_push() {
  ops_terraform_build "$@"
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  push_to_nexus "${ARTIFACT}.${EXTENSION}" "${NEXUS_REPO_TESSELLOPS_ARTIFACTS}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION}"
  generate_checksum "${ARTIFACT}.${EXTENSION}"
  set +e
}

ops_ui_build() {
  gradlew_ui_build
}

ops_ui_build_and_push() {
  set -e
  ARTIFACT="${1}"
  EXT="${2}"
  sed -i 's/^export const ENV = EnvType\.Development;$/export const ENV = EnvType.Production;/g' ./src/constants/env.ts
  gradlew_ui_build
  push_to_nexus "./build/libs/tessellops-ui-${LATEST_TAG}.zip" "${NEXUS_REPO_TESSELLOPS_ARTIFACTS}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXT}"
  generate_checksum $ARTIFACT "tessellops-ui-${LATEST_TAG}.zip"
  set +e
}

parse_coverage_report() {
  set -e
  language=$(yq '.language' convoy.yaml)
  if [[ "${language}" == "java" ]]; then
    parse_coverage_report_java "$@"
  elif [[ "${language}" == "python" ]]; then
    parse_coverage_report_python "$@"
  else
    echo "Code coverage currently not supported for ${language} based repositories"
  fi
}

parse_and_push_coverage_report() {
  set -e
  language=$(yq '.language' convoy.yaml)
  if [[ "${language}" == "java" ]]; then
    parse_and_push_coverage_report_java "$@"
  elif [[ "${language}" == "python" ]]; then
    parse_and_push_coverage_report_python "$@"
  else
    echo "Code coverage currently not supported for ${language} based repositories"
  fi
}

parse_coverage_report_python() {
  if [ -f "pytest.ini" ]; then
    echo "Running python Unit test and generating code coverage report"
    run_python_unit_test "$@"
    coverage_report=$(find . -type f -name "coverage.json")
    coverage_html=$(dirname "${coverage_report}")/htmlcov/index.html
    covered_branches=$(jq '.totals.covered_branches' ${coverage_report})
    missing_branches=$(jq '.totals.missing_branches' ${coverage_report})
    total_branches=$(jq '.totals.num_branches' ${coverage_report})
    branch_coverage_percentage=$(echo "scale=2; ${covered_branches} / ${total_branches} * 100" | bc)
    covered_statements=$(jq '.totals.covered_lines' ${coverage_report})
    missing_statements=$(jq '.totals.missing_lines' ${coverage_report})
    total_statements=$(jq '.totals.num_statements' ${coverage_report})
    statement_coverage_percentage=$(jq '.totals.percent_covered' ${coverage_report} | awk '{print int($1)}')
    export BRANCH_COVERAGE="${covered_branches} ${missing_branches} ${total_branches} ${branch_coverage_percentage%.*}"
    export STATEMENT_COVERAGE="${covered_statements} ${missing_statements} ${total_statements} ${statement_coverage_percentage}"
    flag=1
  else
    echo "pytest.ini not present skipping unit test and code coverage report generation"
  fi
}

parse_and_push_coverage_report_python() {
  flag=0
  parse_coverage_report_python
  if [[ ${DEV_BUILD} == false && ${flag} -eq 1 ]]; then
    echo "Pushing coverage report to S3"
    configure_and_push_aws ${AWS_ACCOUNT_CODE_COVERAGE} ${CODE_COVERAGE_S3} ${coverage_report} "s3://${CODE_COVERAGE_S3}/${LABEL}/${REPO}/coverage-report-${LATEST_TAG}.json"
    configure_and_push_aws ${AWS_ACCOUNT_CODE_COVERAGE} ${CODE_COVERAGE_S3} ${coverage_html} "s3://${CODE_COVERAGE_S3}/${LABEL}/${REPO}/coverage-report-${LATEST_TAG}.html" 
  fi
}

parse_coverage_report_java() {
  jacoco_dir=$(find . -type d -path '*/site/jacoco')
  if [ -z "${jacoco_dir}" ]; then
    echo "No site/jacoco folder found. Skipping coverage report parsing."
    return
  fi
  xml_file="${jacoco_dir}/jacoco.xml"
  branch_covered=$(xmllint --xpath 'sum(//counter[@type="BRANCH"]/@covered)' "${xml_file}")
  branch_missed=$(xmllint --xpath 'sum(//counter[@type="BRANCH"]/@missed)' "${xml_file}")
  branch_total=$((branch_covered + branch_missed))
  branch_percentage=$(echo "scale=0; ${branch_covered} * 100 / ${branch_total}" | bc)
  statement_covered=$(xmllint --xpath 'sum(//counter[@type="INSTRUCTION"]/@covered)' "${xml_file}")
  statement_missed=$(xmllint --xpath 'sum(//counter[@type="INSTRUCTION"]/@missed)' "${xml_file}")
  statement_total=$((statement_covered + statement_missed))
  statement_percentage=$(echo "scale=0; ${statement_covered} * 100 / ${statement_total}" | bc)
  export BRANCH_COVERAGE="${branch_covered} ${branch_missed} ${branch_total} ${branch_percentage}"
  export STATEMENT_COVERAGE="${statement_covered} ${statement_missed} ${statement_total} ${statement_percentage}"
  echo "BRANCH_COVERAGE=\"${BRANCH_COVERAGE}\""
  echo "STATEMENT_COVERAGE=\"${STATEMENT_COVERAGE}\""
  cd ${jacoco_dir}/..
  zip -r coverage.zip jacoco/*
  cd -
  mv ${jacoco_dir}/../coverage.zip ./
  flag=1
}

parse_and_push_coverage_report_java() {
  flag=0
  parse_coverage_report_java
  if [[ ${DEV_BUILD} == false && ${flag} -eq 1 ]]; then
    echo "Pushing coverage report to S3"
    configure_and_push_aws ${AWS_ACCOUNT_CODE_COVERAGE} ${CODE_COVERAGE_S3} "coverage.zip" "s3://${CODE_COVERAGE_S3}/${LABEL}/${REPO}/coverage-report-${LATEST_TAG}.zip"
  fi
}

provider_build() {
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  required_inputs="1 2"
  validate_inputs "${required_inputs}" "$@" 
  install_go_dependencies
  make build
  ls $GOPATH/bin
  cd $GOPATH/bin
  zip -r ${ARTIFACT}.${EXTENSION} terraform-provider-azurerm
  cd -
  mv $GOPATH/bin/${ARTIFACT}.${EXTENSION} .
  set +e
}

provider_build_and_push() {
  provider_build "$@"
  set -e
  push_release_manifest_artifacts
  set +e
}

push_release_manifest_artifacts() {
  local source_file_name=${1:-"${ARTIFACT}.${EXTENSION}"}
  local source_file_path=${2:-"${ARTIFACT}.${EXTENSION}"}
  local artifact_dest_path=${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION}
  local push_to=$(yq ".generates.artifacts[] | select(.name == \"${ARTIFACT}\") | .pushTo // s3" convoy.yaml)
  local release=$(echo ${LABEL} | cut -d'.' -f2)

  upload_artifact ${source_file_path} ${artifact_dest_path} ${push_to}

  if ! ${DEV_BUILD}; then
    aws_configure_prod_assets && aws s3 cp "${source_file_path}" s3://${TESSELLTOOLS_S3}/${artifact_dest_path}
    
    if [[ ${release} -le 134 ]]; then
      for ENV in "${environments[@]}"
      do
        push_to_minio "${source_file_path}" "minio_ci/tessell-artifacts-${ENV}/${artifact_dest_path}"
      done
    fi
    if [[ ${source_file_name} == "${ARTIFACT}.${EXTENSION}" ]]; then
      generate_checksum "${source_file_name}"
    else
      generate_checksum "${ARTIFACT}" "${source_file_name}"
    fi
  fi
}

push_terraform_modules() {
  local artifact_dest_path=${LABEL}/${DIR}/${DIR}-${VERSION}.zip
  local release=$(echo ${LABEL} | cut -d'.' -f2)

  if [[ ${APP_GROUP} == ${TESSELL_GCP_APP_NAME} ]]; then
    push_to_gcloud "${ARTIFACT_FILE}" "gs://tessellgcp-artifacts/${artifact_dest_path}"
  else
    mvn_deploy "${DIR}" "zip" "${ARTIFACT_FILE}" "tessell.terraform_modules" "${VERSION}"
    upload_artifact ${ARTIFACT_FILE} ${artifact_dest_path}
    if ! ${DEV_BUILD}; then
      configure_and_push_aws ${AWS_ACCOUNT_TESSELL_DEV} ${TESSELL_TERRAFORM_MODULES_TERLS_S3} ${ARTIFACT_FILE} s3://${TESSELL_TERRAFORM_MODULES_TERLS_S3}/${artifact_dest_path}
      configure_and_push_aws ${AWS_ACCOUNT_TESSELL_QA} ${TESSELL_TERRAFORM_MODULES_BARC_S3} ${ARTIFACT_FILE} s3://${TESSELL_TERRAFORM_MODULES_BARC_S3}/${artifact_dest_path}
      configure_and_push_aws ${AWS_ACCOUNT_TESSELL_STAGE} ${TESSELL_TERRAFORM_MODULES_STAGE_S3} ${ARTIFACT_FILE} s3://${TESSELL_TERRAFORM_MODULES_STAGE_S3}/${artifact_dest_path}
      configure_and_push_aws ${AWS_ACCOUNT_TESSELL_PROD} ${TESSELL_TERRAFORM_MODULES_BETA_S3} ${ARTIFACT_FILE} s3://${TESSELL_TERRAFORM_MODULES_BETA_S3}/${artifact_dest_path}
      if [[ ${release} -le 134 ]]; then
        for ENV in "${environments[@]}"
        do
          push_to_minio "${ARTIFACT_FILE}" "minio_ci/tessell-artifacts-${ENV}/${artifact_dest_path}"
        done
      fi
    fi
  fi
}

push_to_gcloud() {
  SOURCE="${1}"
  DESTINATION="${2}"
  gcloud auth activate-service-account --key-file=${GOOGLE_GHA_CREDS_PATH}
  gcloud storage cp -r ${SOURCE} ${DESTINATION} --project=${TESSELL_GCP_PROJECT_ID}
}

push_to_minio() {
  SOURCE="${1}"
  DESTINATION="${2}"
  MAX_RETRIES=5
  RETRY_DELAY=3
  local attempt=0
  while [ ${attempt} -lt ${MAX_RETRIES} ]; do
    mc cp "${SOURCE}" "${DESTINATION}"
    if [ $? -eq 0 ]; then
      echo "Artifact successfully pushed to minio ${DESTINATION}."
      return
    else
      attempt=$((attempt + 1))
      echo "Pushing artifact to minio failed. Attempt ${attempt} of ${MAX_RETRIES}. Retrying in ${RETRY_DELAY} seconds."
      sleep ${RETRY_DELAY}
    fi
  done
  echo "Pushing artifact to minio failed after ${MAX_RETRIES} attempts."
  return 1
}

push_to_nexus() {
  FILE_PATH="${1}"
  URL_PATH="${2}"
  required_inputs="1 2"
  validate_inputs "${required_inputs}" "$@" 
  RESPONSE=$(curl -v -u ${NEXUS_USERNAME}:${NEXUS_PASSWORD} \
      --upload-file ${FILE_PATH}  -w "%{http_code}" \
      ${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${URL_PATH})
  echo ${REPONSE}
  HTTP_CODE=$(echo "${RESPONSE}" | tail -n1)
  validate_reponse_code "${HTTP_CODE}" "201"
}

python_docker_build_and_push() {
  set -e
  IMAGE="$1"
  required_inputs="1"
  validate_inputs "$required_inputs" "$@"
  gradlew_docker_tag
  docker push ${DOCKERHUB_ORG}/$IMAGE:${LATEST_TAG}
  set +e
}

python_library_build() {
  set -e
  initialize_python_build_env "$@"
  gradlew_pythonwheel
  set +e
}

python_library_build_and_push() {
  set -e
  initialize_python_build_env "$@"
  gradlewTwineUpload
  set +e
}

python_setup_build() {
  if [ -f requirements.txt ]; then
    install_python_dependencies
  fi
  VERSION="${3}"
  python3 setup.py bdist_wheel --version ${VERSION}
}

python_setup_build_and_push() {
  if [ -f requirements.txt ]; then 
    install_python_dependencies 
  fi
  ARTIFACT="${1}"
  EXTENSION="${2}"
  VERSION="${3}"
  underscore_artifact_name="${ARTIFACT//-/_}"
  python3 setup.py bdist_wheel --version ${VERSION}
  twine upload --repository-url ${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PUSH_REPOS_PY}/ \
    --username ${NEXUS_USERNAME} \
    --password ${NEXUS_PASSWORD} \
    dist/${underscore_artifact_name}-${VERSION}-py3-none-any.${EXTENSION}
}

qa_build_and_push(){
  set -e
  required_inputs="1 3"
  validate_inputs "${required_inputs}" "$@" 
  setup_qa_env
  export GITHUB_TOKEN="${GITHUB_TOKEN}"
  cp configs/qabusiness.json config.json
  source qavenv/bin/activate
  make clients -B
  source qavenv/bin/activate
  python3 ./main.py ./testcases -s -v --dry-run --run-long-tests --business-edition
  deactivate
  # if [[ ${CHANGED_FILES_ANY_MODIFIED} == 'true' ]]; then
  cd scripts
  docker_build_and_push $@
  cd ..
  # fi
  set +e
}

run_python_unit_test() {
  initialise_coverage 'test-venv'
  python_version=$(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
  source_path=${venv_path}/lib/python${python_version}/site-packages/
  include=$(yq '.codeCoverage.report.include | join(",")' convoy.yaml)
  pushd ${source_path}
  echo "Running unit tests"
  python -m coverage run --branch --source "." -m pytest tests
  echo "Generating code coverage report"
  python -m coverage report --skip-empty --include="${include}"
  python -m coverage html --include="${include}"
  python -m coverage json --include="${include}"
  popd
  deactivate 
}

setup_qa_env() {
  INSTALL_DIR=/usr/local/bin
  sudo mkdir -p ${INSTALL_DIR}/openapitools
  curl https://raw.githubusercontent.com/OpenAPITools/openapi-generator/master/bin/utils/openapi-generator-cli.sh > openapi-generator-cli
  sudo cp openapi-generator-cli ${INSTALL_DIR}/openapitools/openapi-generator-cli
  sudo chmod 755 ${INSTALL_DIR}/openapitools/openapi-generator-cli
  sudo ln -f -s ${INSTALL_DIR}/openapitools/openapi-generator-cli ${INSTALL_DIR}/openapi-generator
  wget https://repo1.maven.org/maven2/org/openapitools/openapi-generator-cli/6.0.0/openapi-generator-cli-6.0.0.jar -O openapi-generator-cli.jar
  python -m pip cache purge
  sudo mv openapi-generator-cli.jar /usr/local/bin/openapi-generator-cli-6.0.0.jar
  python -m pip install --user virtualenv --trusted-host ${NEXUS_SERVER_ENDPOINT}
  python -m pip install yq wheel --trusted-host ${NEXUS_SERVER_ENDPOINT}
  python -m venv qavenv
  source qavenv/bin/activate
  python -m pip install wheel --trusted-host ${NEXUS_SERVER_ENDPOINT}
  python -m pip install -r scripts/requirements.txt --trusted-host ${NEXUS_SERVER_ENDPOINT} --extra-index-url=${NEXUS_PROTOCOL}://${NEXUS_USERNAME}:${NEXUS_PASSWORD}@${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PULL_REPOS_PY}/simple
  python -m pip list | grep harness
  deactivate
}

setup_packer_env() {
  python -m pip uninstall -y packer_framework
  python -m pip install --user virtualenv
  python -m venv pkenv
  source pkenv/bin/activate
  python -m pip install wheel
  python -m pip install -r ./requirements.txt --trusted-host ${NEXUS_SERVER_ENDPOINT} --extra-index-url=${NEXUS_PROTOCOL}://${NEXUS_USERNAME}:${NEXUS_PASSWORD}@${NEXUS_SERVER_ENDPOINT}/repository/${NEXUS_PULL_REPOS_PY}/simple
}

software_def_build() {
  set -e
  setup_packer_env
  export CURRENT_VERSION_TAG="0.0.0"
  export WORKDIR="/tmp/software_manifest_workdir"
  rm -rf  "${WORKDIR}" && mkdir -p "${WORKDIR}"
  mkdir -p ~/.packer.d/plugins
  assert_base_branch_commit_success
  get_previous_commited_software_manifest
  if [[ "$BRANCH_NAME" == *double_commit* ]]; then
    echo "${BRANCH_NAME} contains double_commit"
    get_dc_root_pr_diff
    assert_root_pr_commit_success
    git diff origin/${GITHUB_BASE_REF} --compact-summary  > ../current_pr_diff
    if [[ ! $(diff ../root_pr_diff ../current_pr_diff) ]]; then
      echo "${BRANCH_NAME} contains double_commit and no pr diff, skipping build"
      set +e
      return
    fi
  fi
  validate_all -r $PWD --dest_branch ${GITHUB_BASE_REF} --src_branch ${SOURCE_BRANCH} --pipeline_run
  build_all_artifacts -r $PWD --dest_branch ${GITHUB_BASE_REF} --src_branch ${SOURCE_BRANCH} --dry_run --pipeline_run
  set +e
}

software_def_build_and_push() {
  set -e
  setup_packer_env
  export CURRENT_VERSION_TAG=${LATEST_TAG}
  export CUSTOM_TAGS='{"TESSELL_ENVIRONMENT": "PRODUCTION", "TESSELL_CREATED_BY": "Convoy"}'
  echo $CURRENT_VERSION_TAG
  mkdir -p ~/.packer.d/plugins
  if [[ "$BRANCH_NAME" == *double_commit* ]]; then
    echo "${BRANCH_NAME} contains double_commit"
    get_dc_root_pr_diff
    git diff HEAD~1 --compact-summary > ../current_pr_diff
    cat ../current_pr_diff
    if [[ ! $(diff ../root_pr_diff ../current_pr_diff) ]]; then
      URL_PATH="${NEXUS_ARTIFACT_REPO}/${base_branch_of_root_pr}/delta-image-manifest/delta-image-manifest-${root_pr_tag}.json"
      echo "${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${URL_PATH}"
      curl -o common_manifest.json --user "${GITHUB_USER}:${GITHUB_TOKEN}" \
       ${NEXUS_PROTOCOL}://${NEXUS_SERVER_ENDPOINT}/repository/${URL_PATH}
    else
      build_all_artifacts -r $PWD --base_commit  --pipeline_run
    fi
  else
    build_all_artifacts -r $PWD --base_commit  --pipeline_run
  fi
  push_to_nexus "./common_manifest.json" "${NEXUS_ARTIFACT_REPO}/${LABEL}/delta-image-manifest/delta-image-manifest-${LATEST_TAG}.json"
  set +e
}

sonar_scan() {
    sonar-scanner \
        -Dsonar.projectKey=${GITHUB_REPOSITORY_OWNER}:${GITHUB_REPO_NAME} \
        -Dsonar.sources=. \
        -Dsonar.host.url=${SONAR_HOST_URL} \
        -Dsonar.login=${SONAR_TOKEN} \
        -Dsonar.java.binaries=. \
        -Dsonar.python.version=3.9 \
        -Dsonar.sourceEncoding=UTF-8 \
        -Dsonar.exclusions='**/*.js,**/*.html,**/*.css,**/*.jar,ci-scripts/**'
}

tailscale_build() {
  set -e
  export GOPROXY=direct
  export GOSUMDB='sum.golang.org'
  go env
  go install tailscale.com/cmd/gitops-pusher@latest
  export TS_API_KEY=${TS_API_KEY}
  export TS_TAILNET=${TS_TAILNET}
  gitops-pusher --policy-file ./policy.hujson test
  set +e
}

tailscale_build_and_push() {
  set -e
  export GOPROXY=direct
  export GOSUMDB='sum.golang.org'
  go env
  go install tailscale.com/cmd/gitops-pusher@latest
  export TS_API_KEY=${TS_API_KEY}
  export TS_TAILNET=${TS_TAILNET}
  if ! ${DEV_BUILD}; then
    gitops-pusher --policy-file ./policy.hujson apply
  fi
  generate_checksum "policy.hujson"
  set +e
}

terraform_apply() {
  set -e
  cd terraform
  generate_sts_session_token ${AWS_ACCOUNT_TESSELL_COMMON_INFRA}
  terraform init
  terraform plan
  cd ..
  unset AWS_ACCESS_KEY_ID AWS_SECRET_ACCESS_KEY AWS_SESSION_TOKEN
  set +e
}

terraform_apply_and_push() {
  set -e
  terraform_apply
  if ! ${DEV_BUILD}; then
    cd terraform
    terraform apply -auto-approve
    cd ..
  fi
  set +e
}

terraform_zip_build() {
  set -e
  ARTIFACT="${1}"
  BUILD_DIR=${2}
  BASE_DIR=${3}
  ARTIFACT_FILE="${ARTIFACT}.zip"
  zip -r ${BUILD_DIR}/${ARTIFACT_FILE} ${BASE_DIR} -x ".git*" "ci-scripts*"
  set +e
}

tsm_zip_build() {
  set -e
  ARTIFACT="${1}"
  required_inputs="1"
  validate_inputs "${required_inputs}" "$@" 
  mkdir -p build; cd tsmv101; terraform_build $PWD ../build/${ARTIFACT}.zip; cd ../build; ls -l;
  unzip -l ${ARTIFACT}.zip
  cd ..
  set +e
}

tsm_zip_build_and_push() {
  tsm_zip_build "$@"
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  VERSION="${3}"
  required_inputs="1 2 3"
  validate_inputs "${required_inputs}" "$@" 
  mvn_deploy "${ARTIFACT}" "${EXTENSION}" "build/${ARTIFACT}.${EXTENSION}" "tessell.tsm.infra" "${VERSION}"
  set +e
}

ui_build() {
  set +e
  install_node
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  VERSION="${3}"
  npm install
  npm run style-check
  npm run build
  cd build
  zip -r ../${ARTIFACT}.${EXTENSION}  *
  cd ..
  ls -lrta ${ARTIFACT}.${EXTENSION}
  set +e
}

ui_build_and_push() {
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  TAG=${LATEST_TAG}
  ui_build ${ARTIFACT} ${EXTENSION} ${TAG}
  set -e
  ARTIFACT_PATH="./${ARTIFACT}.${EXTENSION}"
  mvn_deploy "${ARTIFACT}" "${EXTENSION}" "${ARTIFACT_PATH}" "convoy.convoy-ui" "${TAG}"
  generate_checksum "${ARTIFACT}.${EXTENSION}"
  set +e
}

upload_folder_to_gcloud() {
  local folder_path=$1
  local recursive=$2
  local temp_dir=""
  local artifact_base_path="gs://${TESSELL_GCP_ARTIFACTS_BUCKET}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}"

  if [[ "$recursive" != "true" ]]; then
    temp_dir=$(mktemp -d)
    for file in "$folder_path"/*; do
      [[ -f $file ]] && cp "$file" "$temp_dir/"
    done
    folder_path=$temp_dir
  fi
  push_to_gcloud "${folder_path}/*" "${artifact_base_path}/"

  zip -r "${ARTIFACT}.zip" "$folder_path"
  push_to_gcloud "${ARTIFACT}.zip" "${artifact_base_path}/${ARTIFACT}.zip"

  [[ -n $temp_dir ]] && rm -rf "$temp_dir"
}

validate_reponse_code() {
  HTTP_CODE="${1}"
  EXPECTED_CODE="${2}"
  echo ${HTTP_CODE}
  HTTP_CODE=$((HTTP_CODE))
  if [ "${HTTP_CODE}" -ne ${EXPECTED_CODE} ]; then
    echo "Error: Unexpected HTTP response code ${HTTP_CODE}"
    exit 1
  fi
}

vss_tar_build() {
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  CLOUD=$(echo "${ARTIFACT}" | awk -F'[-]' '{print $3}')
  DIR="build_${CLOUD}"
  mkdir ${DIR}
  cp -r  ./tessell-vss-requestor/TessellVssRequestor.exe ./tessell-vss-provider/${CLOUD}/install-provider ${DIR}
  cd ${DIR}
  tar -cf ../${ARTIFACT}.${EXTENSION} .
  cd ..
  ls
  set +e
}

vss_tar_build_and_push() {
  vss_tar_build "$@"
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  mvn_deploy "${ARTIFACT}" "${EXTENSION}" "./${ARTIFACT}.${EXTENSION}" "tessell.vss" "${LATEST_TAG}"
  push_release_manifest_artifacts
  set +e
}

validate_inputs() {
  local required=($1)
  shift
  for index in "${required[@]}"; do
    if [ -z "${!index}" ]; then
      echo "Error: Required Argument at index ${index} is null or empty."
      exit 1
    fi
  done
}

yarn_build() {
  install_node
  set -e
  DIR=${1}
  BASE_DIR=$PWD
  cd ${DIR}
  yarn install
  yarn build
  cd ${BASE_DIR}
  set +e
}

yarn_build_and_push() {
  set -e
  DIR=${1}
  if [ -f "${DIR}/build.sh" ]; then
    ./${DIR}/build.sh
  fi
  zip_file_and_push "$@"
  set +e
}

# Usage:
# generates:
#   - buildFunction: zip
#     zipDirectory: tessell-hcp-setup (To have contents of this directory at root of zip)
#     zipDirectory: [tessell-hcp-setup, tessell/worker] (To have these two directories at root of zip, `tessell/worker` path would be preserved in zip)
zip_build() {
  set -e
  ARTIFACT="${1}"
  zip_dirs=$(yq ".generates.artifacts[] | select(.name == \"${ARTIFACT}\") | .zipDirectory" convoy.yaml)
  if [[ -z ${zip_dirs} || ${zip_dirs} == "null" ]]; then
    echo "‚ùå No zipDirectory found for artifact: ${ARTIFACT}"
    exit 1
  fi
  dirs=("${zip_dirs}")
  if [[ "${zip_dirs}" =~ ^\[ ]]; then
    mapfile -t dirs < <(echo "${zip_dirs}" | yq -r '.[]')
  fi
  OUTPUT_ZIP="$(pwd)/${ARTIFACT}.zip"
  if [[ ${#dirs[@]} -eq 1 ]]; then
    (cd "${dirs[0]}" && zip -r "${OUTPUT_ZIP}" .)
  else
    zip -r "${OUTPUT_ZIP}" "${dirs[@]}"
  fi
  set +e
}

zip_build_and_push() {
  zip_build "$@"
  set -e
  ARTIFACT=${1}
  EXTENSION=${2}
  push_release_manifest_artifacts
  set +e
}

zip_directory() {
  DIR="${1}"
  ARTIFACT_FILE="${2}"
  zip -r ${ARTIFACT_FILE} ${DIR}
}

zip_file() {
  set -e
  DIR=${1}
  BASE_DIR=$PWD
  cd ${DIR}
  zip -r ${BASE_DIR}/${DIR}.zip ./
  cd ${BASE_DIR}
  set +e  
}

zip_file_and_push() {
  zip_file "$@"
  set -e
  ARTIFACT="${1}"
  EXTENSION="${2}"
  if ! ${DEV_BUILD}; then
    if [[ ${APP_GROUP} == ${TESSELL_GCP_APP_NAME} ]]; then
      push_to_gcloud "${ARTIFACT}.${EXTENSION}" "gs://${TESSELL_GCP_ARTIFACTS_BUCKET}/${LABEL}/${ARTIFACT}/${ARTIFACT}-${LATEST_TAG}.${EXTENSION}"
      generate_checksum "${ARTIFACT}.${EXTENSION}"
    else
      push_release_manifest_artifacts
    fi
  fi
  set +e  
}
